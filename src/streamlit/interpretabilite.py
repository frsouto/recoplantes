import streamlit as st
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from PIL import Image, ImageEnhance, ImageFilter
import lime
from lime import lime_image
from skimage.segmentation import mark_boundaries
import plotly.graph_objects as go
import time
import gc
import pandas as pd
from utils.classes import class_names
from utils.config_loader import load_model_configs

# Configuration de la page - DOIT √äTRE EN PREMIER
st.set_page_config(layout="wide", page_title="Classification d'Images IA")

def load_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

load_css("utils/styles.css")

@st.cache_resource
def load_model(model_name):
    return tf.keras.models.load_model(model_name)


MODEL_CONFIGS = load_model_configs("utils/model_configs.json")

def preprocess_image(img, model_choice, for_lime=False):
    """Pr√©traite l'image selon le mod√®le choisi."""
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    
    if MODEL_CONFIGS[model_choice]["preprocessing"] == "simple":
        return img_array / 255.0
    else:  # Pour MobileNet
        if for_lime:
            # Pour LIME, on normalise simplement entre 0 et 1
            return img_array / 255.0
        else:
            # Pour la pr√©diction normale, on utilise le pr√©traitement MobileNet
            return tf.keras.applications.mobilenet.preprocess_input(img_array)

def create_lime_predictor(model, model_choice):
    """Cr√©e une fonction de pr√©diction adapt√©e pour LIME."""
    def predictor(images):
        # Convertir le batch d'images en float et le normaliser
        processed_images = []
        for img in images:
            # Assurer que l'image est en float et normalis√©e entre 0 et 1
            if img.dtype != np.float32:
                img = img.astype(np.float32)
            if img.max() > 1.0:
                img = img / 255.0
            
            # Appliquer le pr√©traitement sp√©cifique au mod√®le
            if MODEL_CONFIGS[model_choice]["preprocessing"] == "mobilenet":
                # Convertir de [0,1] au format attendu par MobileNet
                img = img * 255.0
                img = tf.keras.applications.mobilenet.preprocess_input(img)
            
            processed_images.append(img)
        
        batch = np.stack(processed_images)
        return model.predict(batch)
    
    return predictor

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None, intensity=4):
    """G√©n√®re la heatmap Grad-CAM."""
    grad_model = tf.keras.models.Model(
        [model.inputs], 
        [model.get_layer(last_conv_layer_name).output, model.output]
    )
    
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        
        pred_index = pred_index.numpy()
        if isinstance(pred_index, np.ndarray):
            if pred_index.size == 1:
                pred_index = pred_index.item()
            else:
                pred_index = pred_index[0]
                
        class_channel = predictions[0][pred_index]
    
    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = heatmap * intensity
    
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def overlay_gradcam(img, heatmap, alpha=0.3):
    """Superpose la heatmap Grad-CAM sur l'image originale."""
    img = img.resize((224, 224))
    img_array = np.array(img)

    heatmap = np.uint8(255 * heatmap)
    jet = plt.cm.get_cmap("inferno")
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]
    jet_heatmap = image.array_to_img(jet_heatmap)
    jet_heatmap = jet_heatmap.resize((img_array.shape[1], img_array.shape[0]))
    jet_heatmap = image.img_to_array(jet_heatmap)

    superimposed_img = jet_heatmap * alpha + img_array
    superimposed_img = image.array_to_img(superimposed_img)
    
    return superimposed_img

def explain_with_lime(img_array, model, model_choice):
    """G√©n√®re l'explication LIME."""
    # Cr√©er un pr√©dicteur adapt√© pour LIME
    predictor = create_lime_predictor(model, model_choice)
    
    explainer = lime_image.LimeImageExplainer()
    explanation = explainer.explain_instance(
        img_array[0].astype('double'),  # Assurer que l'image est en double pr√©cision
        predictor,
        top_labels=1,
        hide_color=0,
        num_samples=15
    )
    
    temp, mask = explanation.get_image_and_mask(
        explanation.top_labels[0],
        positive_only=True,
        num_features=10,
        hide_rest=True
    )
    
    # S'assurer que l'image est normalis√©e entre 0 et 1
    if temp.max() > 1.0:
        temp = temp / 255.0
        
    return mark_boundaries(temp, mask)

def predict_with_model(img, model, model_choice):
    """Effectue la pr√©diction avec le mod√®le sp√©cifi√©."""
    start_time = time.time()
    processed_img = preprocess_image(img, model_choice)
    predictions = model.predict(processed_img)
    end_time = time.time()
    
    return predictions, end_time - start_time

def display_results(predictions, analysis_time, class_names):
    """Affiche les r√©sultats de la pr√©diction."""
    predicted_class_index = tf.argmax(predictions[0])
    predicted_class_name = class_names[predicted_class_index.numpy()]
    
    metric1, metric2 = st.columns(2)
    with metric1:
        st.metric("Classe pr√©dite", predicted_class_name)
    with metric2:
        st.metric("Temps d'analyse", f"{analysis_time:.2f}s")
    
    st.markdown("#### üìä Top 5 des pr√©dictions")
    top_5_indices = np.argsort(predictions[0])[-5:][::-1]
    
    fig = go.Figure(go.Bar(
        x=[predictions[0][i] * 100 for i in top_5_indices],
        y=[class_names[i] for i in top_5_indices],
        orientation='h',
        marker=dict(
            color='rgba(74, 124, 89, 0.8)',
            line=dict(color='rgba(74, 124, 89, 1.0)', width=2)
        )
    ))
    
    fig.update_layout(
        title=dict(text="Probabilit√©s de classification", x=0.5, xanchor='center'),
        xaxis_title="Probabilit√© (%)",
        yaxis=dict(autorange="reversed"),
        height=300,
        margin=dict(l=20, r=20, t=40, b=20),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
    )
    
    st.plotly_chart(fig, use_container_width=True)
    return predicted_class_name

def generate_interpretability(img, model, model_choice, option, predicted_class_name):
    """G√©n√®re la visualisation d'interpr√©tabilit√© selon la m√©thode choisie."""
    processed_img = preprocess_image(img, model_choice)
    
    if option == 'Grad-CAM':
        heatmap = make_gradcam_heatmap(
            processed_img,
            model,
            MODEL_CONFIGS[model_choice]["last_conv_layer"],
            intensity=3
        )
        gradcam_image = overlay_gradcam(img, heatmap, alpha=0.7)
        st.image(
            gradcam_image,
            caption=f'Carte de chaleur Grad-CAM : {predicted_class_name}',
            use_column_width=True
        )
    else:
        with st.spinner('G√©n√©ration de l\'explication LIME...'):
            processed_img = preprocess_image(img, model_choice, for_lime=True)
            lime_img = explain_with_lime(processed_img, model, model_choice)
            st.image(
                lime_img,
                caption=f'Zones d\'importance LIME : {predicted_class_name}',
                use_column_width=True,
                clamp=True  # Ajouter clamp=True pour √©viter l'erreur
            )

def compare_models(img, selected_models, class_names, interpretation_method='Grad-CAM'):
    """
    Compare les pr√©dictions de plusieurs mod√®les sur une m√™me image avec choix de la m√©thode d'interpr√©tabilit√©.
    
    Args:
        img: Image PIL √† analyser
        selected_models: Liste des mod√®les s√©lectionn√©s
        class_names: Liste des noms de classes
        interpretation_method: 'Grad-CAM' ou 'LIME'
    """
    cols = st.columns(len(selected_models))
    results = {}
    
    # Pr√©parer l'image une seule fois
    img_display = img.resize((224, 224))
    
    for idx, model_name in enumerate(selected_models):
        with cols[idx]:
            st.markdown(f"##### {model_name}")
            
            # Charger le mod√®le
            model = load_model(MODEL_CONFIGS[model_name]["path"])
            
            # Faire la pr√©diction
            predictions, analysis_time = predict_with_model(img_display, model, model_name)
            pred_index = tf.argmax(predictions[0])
            confidence = predictions[0][pred_index] * 100
            
            # Afficher les m√©triques
            st.metric("Classe", class_names[pred_index])
            st.metric("Confiance", f"{confidence:.1f}%")
            st.metric("Temps", f"{analysis_time:.3f}s")
            
            # G√©n√©rer la visualisation d'interpr√©tabilit√©
            if interpretation_method == 'Grad-CAM':
                heatmap = make_gradcam_heatmap(
                    preprocess_image(img_display, model_name),
                    model,
                    MODEL_CONFIGS[model_name]["last_conv_layer"],
                    intensity=3
                )
                viz_image = overlay_gradcam(img_display, heatmap, alpha=0.7)
                st.image(viz_image, caption="Grad-CAM", use_column_width=True)
            else:  # LIME
                with st.spinner(f'G√©n√©ration LIME pour {model_name}...'):
                    processed_img = preprocess_image(img_display, model_name, for_lime=True)
                    lime_img = explain_with_lime(processed_img, model, model_name)
                    st.image(
                        lime_img,
                        caption="LIME",
                        use_column_width=True,
                        clamp=True
                    )
            
            # Stocker les r√©sultats
            results[model_name] = {
                "class": class_names[pred_index],
                "confidence": confidence,
                "time": analysis_time
            }
    
    return results

def main():
    # Container principal avec marge
    with st.container():
        # Titre principal
        st.markdown("""
            <div class='main-title'>
                <h1>Classification d'Image avec Comparaison de Mod√®les</h1>
            </div>
        """, unsafe_allow_html=True)

        # Param√®tres dans la sidebar
        with st.sidebar:
            st.markdown("### üìä Configuration")
            
            # Multi-s√©lection des mod√®les
            selected_models = st.multiselect(
                "S√©lectionner les mod√®les √† comparer",
                list(MODEL_CONFIGS.keys()),
                default=["CNN Maison", "Mobilenet1FineTuned"],
                help="S√©lectionnez au moins un mod√®le"
            )
            
            # S√©lection de la m√©thode d'interpr√©tabilit√©
            interpretation_method = st.radio(
                "üîç M√©thode d'interpr√©tabilit√©",
                ('Grad-CAM', 'LIME'),
                help="Choisissez la m√©thode de visualisation"
            )
            
            if interpretation_method == 'LIME':
                st.warning("‚ö†Ô∏è L'analyse LIME peut prendre plus de temps")
            
            # V√©rification du nombre de mod√®les s√©lectionn√©s
            if len(selected_models) == 0:
                st.warning("‚ö†Ô∏è Veuillez s√©lectionner au moins un mod√®le")
            elif len(selected_models) > 3:
                st.warning("‚ö†Ô∏è Veuillez s√©lectionner maximum 3 mod√®les")
            
            # Upload de l'image
            st.markdown("### üì§ Image √† analyser")
            uploaded_file = st.file_uploader(
                "",
                type=["jpg", "jpeg", "png"],
                help="Formats support√©s: JPG, JPEG, PNG"
            )
            
            # Param√®tres d'image
            if uploaded_file:
                st.markdown("### ‚öôÔ∏è Param√®tres d'image")
                brightness = st.slider("üîÜ Luminosit√©", 0.5, 2.0, 1.0)
                rotation_angle = st.slider("üîÑ Rotation", 0, 360, 0)
                blur_intensity = st.slider("üå´Ô∏è Flou", 0, 5, 0)

        # Zone principale
        if uploaded_file and 0 < len(selected_models) <= 3:
            # Charger et pr√©traiter l'image
            img = Image.open(uploaded_file)
            
            # Appliquer les transformations
            img = ImageEnhance.Brightness(img).enhance(brightness)
            if blur_intensity > 0:
                img = img.filter(ImageFilter.GaussianBlur(blur_intensity))
            if rotation_angle != 0:
                img = img.rotate(rotation_angle, expand=True)
            
            # Afficher l'image originale
            st.markdown("### üñºÔ∏è Image analys√©e")
            st.image(img, caption='Image source', use_column_width=True)
            
            # Bouton d'analyse avec indication de la m√©thode
            if st.button(f"üöÄ Lancer l'analyse comparative ({interpretation_method})", type="primary"):
                st.markdown("### üìä R√©sultats de la comparaison")
                
                with st.spinner(f'Analyse comparative avec {interpretation_method} en cours...'):
                    # Lancer la comparaison des mod√®les avec la m√©thode s√©lectionn√©e
                    results = compare_models(img, selected_models, class_names, interpretation_method)
                
                # Afficher un tableau r√©capitulatif
                st.markdown("### üìã R√©capitulatif")
                df_results = pd.DataFrame.from_dict(results, orient='index')
                st.dataframe(
                    df_results.style.format({
                        'confidence': '{:.1f}%',
                        'time': '{:.3f}s'
                    }),
                    use_container_width=True
                )

if __name__ == "__main__":
    main()
